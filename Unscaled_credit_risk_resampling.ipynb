{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Resampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"loan_amnt\", \"int_rate\", \"installment\", \"home_ownership\",\n",
    "    \"annual_inc\", \"verification_status\", \"issue_d\", \"loan_status\",\n",
    "    \"pymnt_plan\", \"dti\", \"delinq_2yrs\", \"inq_last_6mths\",\n",
    "    \"open_acc\", \"pub_rec\", \"revol_bal\", \"total_acc\",\n",
    "    \"initial_list_status\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\",\n",
    "    \"total_pymnt_inv\", \"total_rec_prncp\", \"total_rec_int\", \"total_rec_late_fee\",\n",
    "    \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_amnt\", \"next_pymnt_d\",\n",
    "    \"collections_12_mths_ex_med\", \"policy_code\", \"application_type\", \"acc_now_delinq\",\n",
    "    \"tot_coll_amt\", \"tot_cur_bal\", \"open_acc_6m\", \"open_act_il\",\n",
    "    \"open_il_12m\", \"open_il_24m\", \"mths_since_rcnt_il\", \"total_bal_il\",\n",
    "    \"il_util\", \"open_rv_12m\", \"open_rv_24m\", \"max_bal_bc\",\n",
    "    \"all_util\", \"total_rev_hi_lim\", \"inq_fi\", \"total_cu_tl\",\n",
    "    \"inq_last_12m\", \"acc_open_past_24mths\", \"avg_cur_bal\", \"bc_open_to_buy\",\n",
    "    \"bc_util\", \"chargeoff_within_12_mths\", \"delinq_amnt\", \"mo_sin_old_il_acct\",\n",
    "    \"mo_sin_old_rev_tl_op\", \"mo_sin_rcnt_rev_tl_op\", \"mo_sin_rcnt_tl\", \"mort_acc\",\n",
    "    \"mths_since_recent_bc\", \"mths_since_recent_inq\", \"num_accts_ever_120_pd\", \"num_actv_bc_tl\",\n",
    "    \"num_actv_rev_tl\", \"num_bc_sats\", \"num_bc_tl\", \"num_il_tl\",\n",
    "    \"num_op_rev_tl\", \"num_rev_accts\", \"num_rev_tl_bal_gt_0\",\n",
    "    \"num_sats\", \"num_tl_120dpd_2m\", \"num_tl_30dpd\", \"num_tl_90g_dpd_24m\",\n",
    "    \"num_tl_op_past_12m\", \"pct_tl_nvr_dlq\", \"percent_bc_gt_75\", \"pub_rec_bankruptcies\",\n",
    "    \"tax_liens\", \"tot_hi_cred_lim\", \"total_bal_ex_mort\", \"total_bc_limit\",\n",
    "    \"total_il_high_credit_limit\", \"hardship_flag\", \"debt_settlement_flag\"\n",
    "]\n",
    "\n",
    "target = [\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68817 entries, 0 to 68816\n",
      "Data columns (total 86 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   loan_amnt                   68817 non-null  float64\n",
      " 1   int_rate                    68817 non-null  float64\n",
      " 2   installment                 68817 non-null  float64\n",
      " 3   home_ownership              68817 non-null  object \n",
      " 4   annual_inc                  68817 non-null  float64\n",
      " 5   verification_status         68817 non-null  object \n",
      " 6   issue_d                     68817 non-null  object \n",
      " 7   loan_status                 68817 non-null  object \n",
      " 8   pymnt_plan                  68817 non-null  object \n",
      " 9   dti                         68817 non-null  float64\n",
      " 10  delinq_2yrs                 68817 non-null  float64\n",
      " 11  inq_last_6mths              68817 non-null  float64\n",
      " 12  open_acc                    68817 non-null  float64\n",
      " 13  pub_rec                     68817 non-null  float64\n",
      " 14  revol_bal                   68817 non-null  float64\n",
      " 15  total_acc                   68817 non-null  float64\n",
      " 16  initial_list_status         68817 non-null  object \n",
      " 17  out_prncp                   68817 non-null  float64\n",
      " 18  out_prncp_inv               68817 non-null  float64\n",
      " 19  total_pymnt                 68817 non-null  float64\n",
      " 20  total_pymnt_inv             68817 non-null  float64\n",
      " 21  total_rec_prncp             68817 non-null  float64\n",
      " 22  total_rec_int               68817 non-null  float64\n",
      " 23  total_rec_late_fee          68817 non-null  float64\n",
      " 24  recoveries                  68817 non-null  float64\n",
      " 25  collection_recovery_fee     68817 non-null  float64\n",
      " 26  last_pymnt_amnt             68817 non-null  float64\n",
      " 27  next_pymnt_d                68817 non-null  object \n",
      " 28  collections_12_mths_ex_med  68817 non-null  float64\n",
      " 29  policy_code                 68817 non-null  float64\n",
      " 30  application_type            68817 non-null  object \n",
      " 31  acc_now_delinq              68817 non-null  float64\n",
      " 32  tot_coll_amt                68817 non-null  float64\n",
      " 33  tot_cur_bal                 68817 non-null  float64\n",
      " 34  open_acc_6m                 68817 non-null  float64\n",
      " 35  open_act_il                 68817 non-null  float64\n",
      " 36  open_il_12m                 68817 non-null  float64\n",
      " 37  open_il_24m                 68817 non-null  float64\n",
      " 38  mths_since_rcnt_il          68817 non-null  float64\n",
      " 39  total_bal_il                68817 non-null  float64\n",
      " 40  il_util                     68817 non-null  float64\n",
      " 41  open_rv_12m                 68817 non-null  float64\n",
      " 42  open_rv_24m                 68817 non-null  float64\n",
      " 43  max_bal_bc                  68817 non-null  float64\n",
      " 44  all_util                    68817 non-null  float64\n",
      " 45  total_rev_hi_lim            68817 non-null  float64\n",
      " 46  inq_fi                      68817 non-null  float64\n",
      " 47  total_cu_tl                 68817 non-null  float64\n",
      " 48  inq_last_12m                68817 non-null  float64\n",
      " 49  acc_open_past_24mths        68817 non-null  float64\n",
      " 50  avg_cur_bal                 68817 non-null  float64\n",
      " 51  bc_open_to_buy              68817 non-null  float64\n",
      " 52  bc_util                     68817 non-null  float64\n",
      " 53  chargeoff_within_12_mths    68817 non-null  float64\n",
      " 54  delinq_amnt                 68817 non-null  float64\n",
      " 55  mo_sin_old_il_acct          68817 non-null  float64\n",
      " 56  mo_sin_old_rev_tl_op        68817 non-null  float64\n",
      " 57  mo_sin_rcnt_rev_tl_op       68817 non-null  float64\n",
      " 58  mo_sin_rcnt_tl              68817 non-null  float64\n",
      " 59  mort_acc                    68817 non-null  float64\n",
      " 60  mths_since_recent_bc        68817 non-null  float64\n",
      " 61  mths_since_recent_inq       68817 non-null  float64\n",
      " 62  num_accts_ever_120_pd       68817 non-null  float64\n",
      " 63  num_actv_bc_tl              68817 non-null  float64\n",
      " 64  num_actv_rev_tl             68817 non-null  float64\n",
      " 65  num_bc_sats                 68817 non-null  float64\n",
      " 66  num_bc_tl                   68817 non-null  float64\n",
      " 67  num_il_tl                   68817 non-null  float64\n",
      " 68  num_op_rev_tl               68817 non-null  float64\n",
      " 69  num_rev_accts               68817 non-null  float64\n",
      " 70  num_rev_tl_bal_gt_0         68817 non-null  float64\n",
      " 71  num_sats                    68817 non-null  float64\n",
      " 72  num_tl_120dpd_2m            68817 non-null  float64\n",
      " 73  num_tl_30dpd                68817 non-null  float64\n",
      " 74  num_tl_90g_dpd_24m          68817 non-null  float64\n",
      " 75  num_tl_op_past_12m          68817 non-null  float64\n",
      " 76  pct_tl_nvr_dlq              68817 non-null  float64\n",
      " 77  percent_bc_gt_75            68817 non-null  float64\n",
      " 78  pub_rec_bankruptcies        68817 non-null  float64\n",
      " 79  tax_liens                   68817 non-null  float64\n",
      " 80  tot_hi_cred_lim             68817 non-null  float64\n",
      " 81  total_bal_ex_mort           68817 non-null  float64\n",
      " 82  total_bc_limit              68817 non-null  float64\n",
      " 83  total_il_high_credit_limit  68817 non-null  float64\n",
      " 84  hardship_flag               68817 non-null  object \n",
      " 85  debt_settlement_flag        68817 non-null  object \n",
      "dtypes: float64(76), object(10)\n",
      "memory usage: 45.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = Path('LoanStats_2019Q1.csv')\n",
    "# first row is link, useless; last two rows we know are empty, can skip now or dropna later\n",
    "df = pd.read_csv(file_path, skiprows=1)[:-2] \n",
    "df = df.loc[:, columns].copy()\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove the `Issued` loan status\n",
    "issued_mask = df['loan_status'] != 'Issued'\n",
    "df = df.loc[issued_mask]\n",
    "\n",
    "# convert interest rate to numerical\n",
    "df['int_rate'] = df['int_rate'].str.replace('%', '')\n",
    "df['int_rate'] = df['int_rate'].astype('float') / 100\n",
    "\n",
    "\n",
    "# Convert the target column values to low_risk and high_risk based on their values\n",
    "x = {'Current': 'low_risk'}   \n",
    "df = df.replace(x)\n",
    "\n",
    "x = dict.fromkeys(['Late (31-120 days)', 'Late (16-30 days)', 'Default', 'In Grace Period'], 'high_risk')\n",
    "#converts 'Late (31-120 days)' to 'high_risk', 'Late(16-30 days)' to 'high_risk', etc\n",
    "df = df.replace(x)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Source Verified', 'Verified', 'Not Verified'], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Poking around and investigating the data\n",
    "\n",
    "#df['verification_status'].unique()\n",
    "#df['issue_d'].unique()\n",
    "#df['home_ownership'].unique()\n",
    "#df.groupby('loan_status').count()\n",
    "#df[\"pymnt_plan\"].unique()\n",
    "#df.groupby(\"pymnt_plan\").count()      #only a single one, can drop?\n",
    "#df[\"initial_list_status\"].unique()\n",
    "#df[\"application_type\"].unique()\n",
    "#df[\"hardship_flag\"].unique()\n",
    "#df.groupby(\"hardship_flag\").count()  #only a single one, can drop?\n",
    "#df[\"loan_amnt\"].duplicated().sum()\n",
    "#df.duplicated(subset=\"hardship_flag\",keep=False).sum()\n",
    "#df.groupby(\"collection_recovery_fee\").count()\n",
    "#df[\"loan_status\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column pymnt_plan is single-valued. The type is object. (1)\n",
      "Column recoveries is single-valued. The type is float64. (2)\n",
      "Column collection_recovery_fee is single-valued. The type is float64. (3)\n",
      "Column policy_code is single-valued. The type is float64. (4)\n",
      "Column acc_now_delinq is single-valued. The type is float64. (5)\n",
      "Column num_tl_120dpd_2m is single-valued. The type is float64. (6)\n",
      "Column num_tl_30dpd is single-valued. The type is float64. (7)\n",
      "Column tax_liens is single-valued. The type is float64. (8)\n",
      "Column hardship_flag is single-valued. The type is object. (9)\n",
      "Column debt_settlement_flag is single-valued. The type is object. (10)\n",
      "['pymnt_plan', 'recoveries', 'collection_recovery_fee', 'policy_code', 'acc_now_delinq', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'tax_liens', 'hardship_flag', 'debt_settlement_flag']\n"
     ]
    }
   ],
   "source": [
    "# check if columns are single-valued, i.e. unimportant to the learning\n",
    "i=0\n",
    "singlevalcols = []\n",
    "for col in columns:\n",
    "    # df.duplicated() returns series of true/falses whether the value is repeated\n",
    "    # adding .sum() adds up all the trues (1s)\n",
    "    # with duplicated(keep=\"first\") (default), each first encounter of a value is counted as duplicated\n",
    "    # if a series is single-valued, the sum will be total length - 1\n",
    "    #       because the value is not a duplicate at the first value\n",
    "    # total length of this df is 68,817\n",
    "    # if a series has at least N possible values, the sum can be total length - N\n",
    "    #        because of N first encounters of each value\n",
    "    # with duplicated(keep=False), even the first encounter of a value is counted as duplicated if there are others\n",
    "    # messes with logic if values are from a set because total sum will always be total length\n",
    "    \n",
    "    if (df.duplicated(subset=col).sum() == 68816):\n",
    "        #if df.groupby(col).count().iloc[0,0] == 68817: #unneeded with re-worked logic above\n",
    "        i+=1\n",
    "        singlevalcols.append(col)\n",
    "        print(f\"Column {col} is single-valued. The type is {df[col].dtype}. ({i})\")\n",
    "\n",
    "print(singlevalcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68817 entries, 0 to 68816\n",
      "Data columns (total 76 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   loan_amnt                   68817 non-null  float64\n",
      " 1   int_rate                    68817 non-null  float64\n",
      " 2   installment                 68817 non-null  float64\n",
      " 3   home_ownership              68817 non-null  object \n",
      " 4   annual_inc                  68817 non-null  float64\n",
      " 5   verification_status         68817 non-null  object \n",
      " 6   issue_d                     68817 non-null  object \n",
      " 7   loan_status                 68817 non-null  object \n",
      " 8   dti                         68817 non-null  float64\n",
      " 9   delinq_2yrs                 68817 non-null  float64\n",
      " 10  inq_last_6mths              68817 non-null  float64\n",
      " 11  open_acc                    68817 non-null  float64\n",
      " 12  pub_rec                     68817 non-null  float64\n",
      " 13  revol_bal                   68817 non-null  float64\n",
      " 14  total_acc                   68817 non-null  float64\n",
      " 15  initial_list_status         68817 non-null  object \n",
      " 16  out_prncp                   68817 non-null  float64\n",
      " 17  out_prncp_inv               68817 non-null  float64\n",
      " 18  total_pymnt                 68817 non-null  float64\n",
      " 19  total_pymnt_inv             68817 non-null  float64\n",
      " 20  total_rec_prncp             68817 non-null  float64\n",
      " 21  total_rec_int               68817 non-null  float64\n",
      " 22  total_rec_late_fee          68817 non-null  float64\n",
      " 23  last_pymnt_amnt             68817 non-null  float64\n",
      " 24  next_pymnt_d                68817 non-null  object \n",
      " 25  collections_12_mths_ex_med  68817 non-null  float64\n",
      " 26  application_type            68817 non-null  object \n",
      " 27  tot_coll_amt                68817 non-null  float64\n",
      " 28  tot_cur_bal                 68817 non-null  float64\n",
      " 29  open_acc_6m                 68817 non-null  float64\n",
      " 30  open_act_il                 68817 non-null  float64\n",
      " 31  open_il_12m                 68817 non-null  float64\n",
      " 32  open_il_24m                 68817 non-null  float64\n",
      " 33  mths_since_rcnt_il          68817 non-null  float64\n",
      " 34  total_bal_il                68817 non-null  float64\n",
      " 35  il_util                     68817 non-null  float64\n",
      " 36  open_rv_12m                 68817 non-null  float64\n",
      " 37  open_rv_24m                 68817 non-null  float64\n",
      " 38  max_bal_bc                  68817 non-null  float64\n",
      " 39  all_util                    68817 non-null  float64\n",
      " 40  total_rev_hi_lim            68817 non-null  float64\n",
      " 41  inq_fi                      68817 non-null  float64\n",
      " 42  total_cu_tl                 68817 non-null  float64\n",
      " 43  inq_last_12m                68817 non-null  float64\n",
      " 44  acc_open_past_24mths        68817 non-null  float64\n",
      " 45  avg_cur_bal                 68817 non-null  float64\n",
      " 46  bc_open_to_buy              68817 non-null  float64\n",
      " 47  bc_util                     68817 non-null  float64\n",
      " 48  chargeoff_within_12_mths    68817 non-null  float64\n",
      " 49  delinq_amnt                 68817 non-null  float64\n",
      " 50  mo_sin_old_il_acct          68817 non-null  float64\n",
      " 51  mo_sin_old_rev_tl_op        68817 non-null  float64\n",
      " 52  mo_sin_rcnt_rev_tl_op       68817 non-null  float64\n",
      " 53  mo_sin_rcnt_tl              68817 non-null  float64\n",
      " 54  mort_acc                    68817 non-null  float64\n",
      " 55  mths_since_recent_bc        68817 non-null  float64\n",
      " 56  mths_since_recent_inq       68817 non-null  float64\n",
      " 57  num_accts_ever_120_pd       68817 non-null  float64\n",
      " 58  num_actv_bc_tl              68817 non-null  float64\n",
      " 59  num_actv_rev_tl             68817 non-null  float64\n",
      " 60  num_bc_sats                 68817 non-null  float64\n",
      " 61  num_bc_tl                   68817 non-null  float64\n",
      " 62  num_il_tl                   68817 non-null  float64\n",
      " 63  num_op_rev_tl               68817 non-null  float64\n",
      " 64  num_rev_accts               68817 non-null  float64\n",
      " 65  num_rev_tl_bal_gt_0         68817 non-null  float64\n",
      " 66  num_sats                    68817 non-null  float64\n",
      " 67  num_tl_90g_dpd_24m          68817 non-null  float64\n",
      " 68  num_tl_op_past_12m          68817 non-null  float64\n",
      " 69  pct_tl_nvr_dlq              68817 non-null  float64\n",
      " 70  percent_bc_gt_75            68817 non-null  float64\n",
      " 71  pub_rec_bankruptcies        68817 non-null  float64\n",
      " 72  tot_hi_cred_lim             68817 non-null  float64\n",
      " 73  total_bal_ex_mort           68817 non-null  float64\n",
      " 74  total_bc_limit              68817 non-null  float64\n",
      " 75  total_il_high_credit_limit  68817 non-null  float64\n",
      "dtypes: float64(69), object(7)\n",
      "memory usage: 39.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Remove / drop the list of singlevalcols\n",
    "\n",
    "df2 = df.drop(labels=singlevalcols, axis=1)\n",
    "\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68817 entries, 0 to 68816\n",
      "Data columns (total 86 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   loan_amnt                            68817 non-null  float64\n",
      " 1   int_rate                             68817 non-null  float64\n",
      " 2   installment                          68817 non-null  float64\n",
      " 3   annual_inc                           68817 non-null  float64\n",
      " 4   loan_status                          68817 non-null  int32  \n",
      " 5   dti                                  68817 non-null  float64\n",
      " 6   delinq_2yrs                          68817 non-null  float64\n",
      " 7   inq_last_6mths                       68817 non-null  float64\n",
      " 8   open_acc                             68817 non-null  float64\n",
      " 9   pub_rec                              68817 non-null  float64\n",
      " 10  revol_bal                            68817 non-null  float64\n",
      " 11  total_acc                            68817 non-null  float64\n",
      " 12  out_prncp                            68817 non-null  float64\n",
      " 13  out_prncp_inv                        68817 non-null  float64\n",
      " 14  total_pymnt                          68817 non-null  float64\n",
      " 15  total_pymnt_inv                      68817 non-null  float64\n",
      " 16  total_rec_prncp                      68817 non-null  float64\n",
      " 17  total_rec_int                        68817 non-null  float64\n",
      " 18  total_rec_late_fee                   68817 non-null  float64\n",
      " 19  last_pymnt_amnt                      68817 non-null  float64\n",
      " 20  collections_12_mths_ex_med           68817 non-null  float64\n",
      " 21  tot_coll_amt                         68817 non-null  float64\n",
      " 22  tot_cur_bal                          68817 non-null  float64\n",
      " 23  open_acc_6m                          68817 non-null  float64\n",
      " 24  open_act_il                          68817 non-null  float64\n",
      " 25  open_il_12m                          68817 non-null  float64\n",
      " 26  open_il_24m                          68817 non-null  float64\n",
      " 27  mths_since_rcnt_il                   68817 non-null  float64\n",
      " 28  total_bal_il                         68817 non-null  float64\n",
      " 29  il_util                              68817 non-null  float64\n",
      " 30  open_rv_12m                          68817 non-null  float64\n",
      " 31  open_rv_24m                          68817 non-null  float64\n",
      " 32  max_bal_bc                           68817 non-null  float64\n",
      " 33  all_util                             68817 non-null  float64\n",
      " 34  total_rev_hi_lim                     68817 non-null  float64\n",
      " 35  inq_fi                               68817 non-null  float64\n",
      " 36  total_cu_tl                          68817 non-null  float64\n",
      " 37  inq_last_12m                         68817 non-null  float64\n",
      " 38  acc_open_past_24mths                 68817 non-null  float64\n",
      " 39  avg_cur_bal                          68817 non-null  float64\n",
      " 40  bc_open_to_buy                       68817 non-null  float64\n",
      " 41  bc_util                              68817 non-null  float64\n",
      " 42  chargeoff_within_12_mths             68817 non-null  float64\n",
      " 43  delinq_amnt                          68817 non-null  float64\n",
      " 44  mo_sin_old_il_acct                   68817 non-null  float64\n",
      " 45  mo_sin_old_rev_tl_op                 68817 non-null  float64\n",
      " 46  mo_sin_rcnt_rev_tl_op                68817 non-null  float64\n",
      " 47  mo_sin_rcnt_tl                       68817 non-null  float64\n",
      " 48  mort_acc                             68817 non-null  float64\n",
      " 49  mths_since_recent_bc                 68817 non-null  float64\n",
      " 50  mths_since_recent_inq                68817 non-null  float64\n",
      " 51  num_accts_ever_120_pd                68817 non-null  float64\n",
      " 52  num_actv_bc_tl                       68817 non-null  float64\n",
      " 53  num_actv_rev_tl                      68817 non-null  float64\n",
      " 54  num_bc_sats                          68817 non-null  float64\n",
      " 55  num_bc_tl                            68817 non-null  float64\n",
      " 56  num_il_tl                            68817 non-null  float64\n",
      " 57  num_op_rev_tl                        68817 non-null  float64\n",
      " 58  num_rev_accts                        68817 non-null  float64\n",
      " 59  num_rev_tl_bal_gt_0                  68817 non-null  float64\n",
      " 60  num_sats                             68817 non-null  float64\n",
      " 61  num_tl_90g_dpd_24m                   68817 non-null  float64\n",
      " 62  num_tl_op_past_12m                   68817 non-null  float64\n",
      " 63  pct_tl_nvr_dlq                       68817 non-null  float64\n",
      " 64  percent_bc_gt_75                     68817 non-null  float64\n",
      " 65  pub_rec_bankruptcies                 68817 non-null  float64\n",
      " 66  tot_hi_cred_lim                      68817 non-null  float64\n",
      " 67  total_bal_ex_mort                    68817 non-null  float64\n",
      " 68  total_bc_limit                       68817 non-null  float64\n",
      " 69  total_il_high_credit_limit           68817 non-null  float64\n",
      " 70  home_ownership_ANY                   68817 non-null  uint8  \n",
      " 71  home_ownership_MORTGAGE              68817 non-null  uint8  \n",
      " 72  home_ownership_OWN                   68817 non-null  uint8  \n",
      " 73  home_ownership_RENT                  68817 non-null  uint8  \n",
      " 74  verification_status_Not_Verified     68817 non-null  uint8  \n",
      " 75  verification_status_Source_Verified  68817 non-null  uint8  \n",
      " 76  verification_status_Verified         68817 non-null  uint8  \n",
      " 77  issue_d_Feb-2019                     68817 non-null  uint8  \n",
      " 78  issue_d_Jan-2019                     68817 non-null  uint8  \n",
      " 79  issue_d_Mar-2019                     68817 non-null  uint8  \n",
      " 80  initial_list_status_f                68817 non-null  uint8  \n",
      " 81  initial_list_status_w                68817 non-null  uint8  \n",
      " 82  next_pymnt_d_Apr-2019                68817 non-null  uint8  \n",
      " 83  next_pymnt_d_May-2019                68817 non-null  uint8  \n",
      " 84  application_type_Individual          68817 non-null  uint8  \n",
      " 85  application_type_Joint_App           68817 non-null  uint8  \n",
      "dtypes: float64(69), int32(1), uint8(16)\n",
      "memory usage: 37.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Transform categorical data to numerical data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# list of categorical features\n",
    "categcols = ['home_ownership', 'verification_status', 'issue_d', 'initial_list_status', 'next_pymnt_d', 'application_type']\n",
    "\n",
    "#len(categcols) # make sure there are 6\n",
    "\n",
    "# transform categorical features\n",
    "df3 = pd.get_dummies(df2, columns=categcols)\n",
    "\n",
    "# remove spaces from column names to be safe\n",
    "df3.rename(columns={'verification_status_Not Verified' : 'verification_status_Not_Verified',\n",
    "                   'verification_status_Source Verified' : 'verification_status_Source_Verified',\n",
    "                   'application_type_Joint App' : 'application_type_Joint_App'},\n",
    "           inplace=True)\n",
    "\n",
    "# fit and transform loan_status column\n",
    "myencoder = LabelEncoder()\n",
    "df3['loan_status'] = myencoder.fit_transform(df3['loan_status'])\n",
    "\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>num_sats</th>\n",
       "      <th>num_tl_90g_dpd_24m</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10500.0</td>\n",
       "      <td>0.1719</td>\n",
       "      <td>375.35</td>\n",
       "      <td>RENT</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>27.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65687.0</td>\n",
       "      <td>38199.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>61987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>929.09</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>20.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>91.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>271427.0</td>\n",
       "      <td>60641.0</td>\n",
       "      <td>41200.0</td>\n",
       "      <td>49197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>529.88</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>24.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60644.0</td>\n",
       "      <td>45684.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>43144.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  installment home_ownership  annual_inc  \\\n",
       "0    10500.0    0.1719       375.35           RENT     66000.0   \n",
       "1    25000.0    0.2000       929.09       MORTGAGE    105000.0   \n",
       "2    20000.0    0.2000       529.88       MORTGAGE     56000.0   \n",
       "\n",
       "  verification_status   issue_d loan_status    dti  delinq_2yrs  ...  \\\n",
       "0     Source Verified  Mar-2019    low_risk  27.24          0.0  ...   \n",
       "1            Verified  Mar-2019    low_risk  20.23          0.0  ...   \n",
       "2            Verified  Mar-2019    low_risk  24.26          0.0  ...   \n",
       "\n",
       "   num_sats  num_tl_90g_dpd_24m  num_tl_op_past_12m  pct_tl_nvr_dlq  \\\n",
       "0       8.0                 0.0                 3.0            85.7   \n",
       "1      17.0                 0.0                 6.0            91.2   \n",
       "2       8.0                 0.0                 4.0            66.7   \n",
       "\n",
       "   percent_bc_gt_75 pub_rec_bankruptcies  tot_hi_cred_lim  total_bal_ex_mort  \\\n",
       "0             100.0                  0.0          65687.0            38199.0   \n",
       "1              50.0                  1.0         271427.0            60641.0   \n",
       "2              50.0                  0.0          60644.0            45684.0   \n",
       "\n",
       "   total_bc_limit  total_il_high_credit_limit  \n",
       "0          2000.0                     61987.0  \n",
       "1         41200.0                     49197.0  \n",
       "2          7500.0                     43144.0  \n",
       "\n",
       "[3 rows x 76 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>...</th>\n",
       "      <th>verification_status_Verified</th>\n",
       "      <th>issue_d_Feb-2019</th>\n",
       "      <th>issue_d_Jan-2019</th>\n",
       "      <th>issue_d_Mar-2019</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>next_pymnt_d_Apr-2019</th>\n",
       "      <th>next_pymnt_d_May-2019</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint_App</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10500.0</td>\n",
       "      <td>0.1719</td>\n",
       "      <td>375.35</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>929.09</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>529.88</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  installment  annual_inc  loan_status    dti  \\\n",
       "0    10500.0    0.1719       375.35     66000.0            1  27.24   \n",
       "1    25000.0    0.2000       929.09    105000.0            1  20.23   \n",
       "2    20000.0    0.2000       529.88     56000.0            1  24.26   \n",
       "\n",
       "   delinq_2yrs  inq_last_6mths  open_acc  pub_rec  ...  \\\n",
       "0          0.0             0.0       8.0      0.0  ...   \n",
       "1          0.0             0.0      17.0      1.0  ...   \n",
       "2          0.0             0.0       8.0      0.0  ...   \n",
       "\n",
       "   verification_status_Verified  issue_d_Feb-2019  issue_d_Jan-2019  \\\n",
       "0                             0                 0                 0   \n",
       "1                             1                 0                 0   \n",
       "2                             1                 0                 0   \n",
       "\n",
       "   issue_d_Mar-2019  initial_list_status_f  initial_list_status_w  \\\n",
       "0                 1                      0                      1   \n",
       "1                 1                      0                      1   \n",
       "2                 1                      0                      1   \n",
       "\n",
       "   next_pymnt_d_Apr-2019  next_pymnt_d_May-2019  application_type_Individual  \\\n",
       "0                      0                      1                            1   \n",
       "1                      0                      1                            1   \n",
       "2                      0                      1                            1   \n",
       "\n",
       "   application_type_Joint_App  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "\n",
       "[3 rows x 86 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    68470\n",
       "0      347\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check encoding\n",
    "\n",
    "display(df2.head(3))\n",
    "display(df3.head(3))\n",
    "\n",
    "###### IMPORTANT ######\n",
    "# 0 : high_risk\n",
    "# 1 : low_risk\n",
    "###### IMPORTANT ######\n",
    "\n",
    "df3['loan_status'].value_counts() # to double check it's the same below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "X = df3.drop(\"loan_status\", axis=1)\n",
    "\n",
    "\n",
    "# Create our target\n",
    "y = df3[\"loan_status\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>...</th>\n",
       "      <th>verification_status_Verified</th>\n",
       "      <th>issue_d_Feb-2019</th>\n",
       "      <th>issue_d_Jan-2019</th>\n",
       "      <th>issue_d_Mar-2019</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>next_pymnt_d_Apr-2019</th>\n",
       "      <th>next_pymnt_d_May-2019</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint_App</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>6.881700e+04</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16677.594562</td>\n",
       "      <td>0.127718</td>\n",
       "      <td>480.652863</td>\n",
       "      <td>8.821371e+04</td>\n",
       "      <td>21.778153</td>\n",
       "      <td>0.217766</td>\n",
       "      <td>0.497697</td>\n",
       "      <td>12.587340</td>\n",
       "      <td>0.126030</td>\n",
       "      <td>17604.142828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148001</td>\n",
       "      <td>0.371696</td>\n",
       "      <td>0.451066</td>\n",
       "      <td>0.177238</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>0.876121</td>\n",
       "      <td>0.383161</td>\n",
       "      <td>0.616839</td>\n",
       "      <td>0.860340</td>\n",
       "      <td>0.139660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10277.348590</td>\n",
       "      <td>0.048130</td>\n",
       "      <td>288.062432</td>\n",
       "      <td>1.155800e+05</td>\n",
       "      <td>20.199244</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.758122</td>\n",
       "      <td>6.022869</td>\n",
       "      <td>0.336797</td>\n",
       "      <td>21835.880400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355104</td>\n",
       "      <td>0.483261</td>\n",
       "      <td>0.497603</td>\n",
       "      <td>0.381873</td>\n",
       "      <td>0.329446</td>\n",
       "      <td>0.329446</td>\n",
       "      <td>0.486161</td>\n",
       "      <td>0.486161</td>\n",
       "      <td>0.346637</td>\n",
       "      <td>0.346637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>30.890000</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9000.000000</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>265.730000</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>13.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6293.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>404.560000</td>\n",
       "      <td>7.300000e+04</td>\n",
       "      <td>19.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12068.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24000.000000</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>648.100000</td>\n",
       "      <td>1.040000e+05</td>\n",
       "      <td>26.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21735.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40000.000000</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>1676.230000</td>\n",
       "      <td>8.797500e+06</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>587191.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          loan_amnt      int_rate   installment    annual_inc           dti  \\\n",
       "count  68817.000000  68817.000000  68817.000000  6.881700e+04  68817.000000   \n",
       "mean   16677.594562      0.127718    480.652863  8.821371e+04     21.778153   \n",
       "std    10277.348590      0.048130    288.062432  1.155800e+05     20.199244   \n",
       "min     1000.000000      0.060000     30.890000  4.000000e+01      0.000000   \n",
       "25%     9000.000000      0.088100    265.730000  5.000000e+04     13.890000   \n",
       "50%    15000.000000      0.118000    404.560000  7.300000e+04     19.760000   \n",
       "75%    24000.000000      0.155700    648.100000  1.040000e+05     26.660000   \n",
       "max    40000.000000      0.308400   1676.230000  8.797500e+06    999.000000   \n",
       "\n",
       "        delinq_2yrs  inq_last_6mths      open_acc       pub_rec  \\\n",
       "count  68817.000000    68817.000000  68817.000000  68817.000000   \n",
       "mean       0.217766        0.497697     12.587340      0.126030   \n",
       "std        0.718367        0.758122      6.022869      0.336797   \n",
       "min        0.000000        0.000000      2.000000      0.000000   \n",
       "25%        0.000000        0.000000      8.000000      0.000000   \n",
       "50%        0.000000        0.000000     11.000000      0.000000   \n",
       "75%        0.000000        1.000000     16.000000      0.000000   \n",
       "max       18.000000        5.000000     72.000000      4.000000   \n",
       "\n",
       "           revol_bal  ...  verification_status_Verified  issue_d_Feb-2019  \\\n",
       "count   68817.000000  ...                  68817.000000      68817.000000   \n",
       "mean    17604.142828  ...                      0.148001          0.371696   \n",
       "std     21835.880400  ...                      0.355104          0.483261   \n",
       "min         0.000000  ...                      0.000000          0.000000   \n",
       "25%      6293.000000  ...                      0.000000          0.000000   \n",
       "50%     12068.000000  ...                      0.000000          0.000000   \n",
       "75%     21735.000000  ...                      0.000000          1.000000   \n",
       "max    587191.000000  ...                      1.000000          1.000000   \n",
       "\n",
       "       issue_d_Jan-2019  issue_d_Mar-2019  initial_list_status_f  \\\n",
       "count      68817.000000      68817.000000           68817.000000   \n",
       "mean           0.451066          0.177238               0.123879   \n",
       "std            0.497603          0.381873               0.329446   \n",
       "min            0.000000          0.000000               0.000000   \n",
       "25%            0.000000          0.000000               0.000000   \n",
       "50%            0.000000          0.000000               0.000000   \n",
       "75%            1.000000          0.000000               0.000000   \n",
       "max            1.000000          1.000000               1.000000   \n",
       "\n",
       "       initial_list_status_w  next_pymnt_d_Apr-2019  next_pymnt_d_May-2019  \\\n",
       "count           68817.000000           68817.000000           68817.000000   \n",
       "mean                0.876121               0.383161               0.616839   \n",
       "std                 0.329446               0.486161               0.486161   \n",
       "min                 0.000000               0.000000               0.000000   \n",
       "25%                 1.000000               0.000000               0.000000   \n",
       "50%                 1.000000               0.000000               1.000000   \n",
       "75%                 1.000000               1.000000               1.000000   \n",
       "max                 1.000000               1.000000               1.000000   \n",
       "\n",
       "       application_type_Individual  application_type_Joint_App  \n",
       "count                 68817.000000                68817.000000  \n",
       "mean                      0.860340                    0.139660  \n",
       "std                       0.346637                    0.346637  \n",
       "min                       0.000000                    0.000000  \n",
       "25%                       1.000000                    0.000000  \n",
       "50%                       1.000000                    0.000000  \n",
       "75%                       1.000000                    0.000000  \n",
       "max                       1.000000                    1.000000  \n",
       "\n",
       "[8 rows x 85 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()\n",
    "#X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    68470\n",
       "0      347\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 51366, 0: 246})\n",
      "Counter({1: 17104, 0: 101})\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Sampling\n",
    "\n",
    "Here, we perform a logistic regression with NO sampling corrections:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create, fit/train, and test logistic regression model\n",
    "noSampModel = LogisticRegression(random_state=1)\n",
    "noSampModel.fit(X_train, y_train)\n",
    "\n",
    "y_pred = noSampModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Model score:  0.9952142912500969\n",
      "Testing Data Model score:  0.9941296134844522\n",
      "Testing Data Balanced score:  0.5049212621215349\n"
     ]
    }
   ],
   "source": [
    "# balanced accuracy score\n",
    "print(\"Training Data Model score: \", noSampModel.score(X_train, y_train))\n",
    "print(\"Testing Data Model score: \", noSampModel.score(X_test, y_test))\n",
    "print(\"Testing Data Balanced score: \", balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,   100],\n",
       "       [    1, 17103]], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.50      0.01      1.00      0.02      0.10      0.01       101\n",
      "          1       0.99      1.00      0.01      1.00      0.10      0.01     17104\n",
      "\n",
      "avg / total       0.99      0.99      0.02      0.99      0.10      0.01     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling\n",
    "\n",
    "In this section, you will compare two oversampling algorithms to determine which algorithm results in the best performance. You will oversample the data using the naive random oversampling algorithm and the SMOTE algorithm. For each algorithm, be sure to complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 51366, 0: 51366})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_ROS_train, y_ROS_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_ROS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "ROSmodel = LogisticRegression(random_state=1)\n",
    "ROSmodel.fit(X_ROS_train, y_ROS_train)\n",
    "\n",
    "y_ROS_pred = ROSmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Model score:  0.6429739516411634\n",
      "Testing Data Model score:  0.6005231037489102\n",
      "Testing Data Balanced score:  0.6711292709018329\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "print(\"Training Data Model score: \", ROSmodel.score(X_ROS_train, y_ROS_train))\n",
    "print(\"Testing Data Model score: \", ROSmodel.score(X_test, y_test))\n",
    "print(\"Testing Data Balanced score: \", balanced_accuracy_score(y_test, y_ROS_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   75,    26],\n",
       "       [ 6847, 10257]], dtype=int64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_ROS_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.01      0.74      0.60      0.02      0.67      0.45       101\n",
      "          1       1.00      0.60      0.74      0.75      0.67      0.44     17104\n",
      "\n",
      "avg / total       0.99      0.60      0.74      0.74      0.67      0.44     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_ROS_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 51366, 0: 51366})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_smote_train, y_smote_train = SMOTE(random_state=1, sampling_strategy='auto').fit_resample(\n",
    "    X_train, y_train)\n",
    "\n",
    "Counter(y_smote_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "smoteModel = LogisticRegression(random_state=1)\n",
    "smoteModel.fit(X_smote_train, y_smote_train)\n",
    "\n",
    "y_smote_pred = smoteModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Model score:  0.6527761554335553\n",
      "Testing Data Model score:  0.6839872130194711\n",
      "Testing Data Balanced score:  0.6589738721299632\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "print(\"Training Data Model score: \", smoteModel.score(X_smote_train, y_smote_train))\n",
    "print(\"Testing Data Model score: \", smoteModel.score(X_test, y_test))\n",
    "print(\"Testing Data Balanced score: \", balanced_accuracy_score(y_test, y_smote_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   64,    37],\n",
       "       [ 5400, 11704]], dtype=int64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.01      0.63      0.68      0.02      0.66      0.43       101\n",
      "          1       1.00      0.68      0.63      0.81      0.66      0.44     17104\n",
      "\n",
      "avg / total       0.99      0.68      0.63      0.81      0.66      0.44     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_smote_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling\n",
    "\n",
    "In this section, you will test an undersampling algorithms to determine which algorithm results in the best performance compared to the oversampling algorithms above. You will undersample the data using the Cluster Centroids algorithm and complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 246, 1: 246})"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_clustcent_train, y_clustcent_train = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_clustcent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "clustcentModel = LogisticRegression(random_state=1)\n",
    "clustcentModel.fit(X_clustcent_train, y_clustcent_train)\n",
    "\n",
    "y_clustcent_pred = clustcentModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Model score:  0.6666666666666666\n",
      "Testing Data Model score:  0.38668991572217376\n",
      "Testing Data Balanced score:  0.5291324940492179\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "print(\"Training Data Model score: \", clustcentModel.score(X_clustcent_train, y_clustcent_train))\n",
    "print(\"Testing Data Model score: \", clustcentModel.score(X_test, y_test))\n",
    "print(\"Testing Data Balanced score: \", balanced_accuracy_score(y_test, y_clustcent_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   68,    33],\n",
       "       [10519,  6585]], dtype=int64)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_clustcent_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.01      0.67      0.38      0.01      0.51      0.27       101\n",
      "          1       1.00      0.38      0.67      0.56      0.51      0.25     17104\n",
      "\n",
      "avg / total       0.99      0.39      0.67      0.55      0.51      0.25     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_clustcent_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination (Over and Under) Sampling\n",
    "\n",
    "In this section, you will test a combination over- and under-sampling algorithm to determine if the algorithm results in the best performance compared to the other sampling algorithms above. You will resample the data using the SMOTEENN algorithm and complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 51361, 1: 46653})"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=1)\n",
    "X_smoteen_train, y_smoteen_train = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_smoteen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "smoteenModel = LogisticRegression(random_state=1)\n",
    "smoteenModel.fit(X_smoteen_train, y_smoteen_train)\n",
    "\n",
    "y_smoteen_pred = smoteenModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Model score:  0.6530393617238354\n",
      "Testing Data Model score:  0.569195001453066\n",
      "Testing Data Balanced score:  0.640608936361363\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "print(\"Training Data Model score: \", smoteenModel.score(X_smoteen_train, y_smoteen_train))\n",
    "print(\"Testing Data Model score: \", smoteenModel.score(X_test, y_test))\n",
    "print(\"Testing Data Balanced score: \", balanced_accuracy_score(y_test, y_smoteen_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  72,   29],\n",
       "       [7383, 9721]], dtype=int64)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_smoteen_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.01      0.71      0.57      0.02      0.64      0.41       101\n",
      "          1       1.00      0.57      0.71      0.72      0.64      0.40     17104\n",
      "\n",
      "avg / total       0.99      0.57      0.71      0.72      0.64      0.40     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_smoteen_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
